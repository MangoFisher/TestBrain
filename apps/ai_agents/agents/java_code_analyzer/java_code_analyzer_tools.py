"""
åŸºäº LangChain çš„å·¥å…·å®šä¹‰ã€‚
å°†ç°æœ‰å·¥å…·å°è£…ä¸º LangChain Tool å¯¹è±¡ã€‚
"""

from typing import Optional, Type, List, Dict, Any
from langchain.tools import BaseTool
from pydantic import BaseModel, Field
from .tools import GitTools, AnalyzerAPITools, SourceCodeTools


# ============================================
# Git å·¥å…·çš„ LangChain å°è£…
# ============================================

class CommitInfoInput(BaseModel):
    """è·å– commit ä¿¡æ¯çš„è¾“å…¥"""
    commit_hash: str = Field(description="commit å“ˆå¸Œå€¼ï¼ˆå®Œæ•´æˆ–çŸ­å“ˆå¸Œï¼‰")


class GetCommitInfoTool(BaseTool):
    """è·å– commit è¯¦ç»†ä¿¡æ¯å·¥å…·"""
    name: str = "get_commit_info"
    description: str = "è·å– commit çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½œè€…ã€æ—¶é—´ã€æäº¤ä¿¡æ¯ç­‰ã€‚å½“éœ€è¦äº†è§£æŸä¸ªå˜æ›´çš„èƒŒæ™¯æ—¶ä½¿ç”¨ã€‚"
    args_schema: Type[BaseModel] = CommitInfoInput
    
    git_tools: GitTools = Field(default=None, exclude=True)
    
    def _run(self, commit_hash: str) -> str:
        """æ‰§è¡Œå·¥å…·"""
        result = self.git_tools.get_commit_info(commit_hash)
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)
    
    async def _arun(self, commit_hash: str) -> str:
        """å¼‚æ­¥æ‰§è¡Œï¼ˆæš‚ä¸æ”¯æŒï¼‰"""
        return self._run(commit_hash)


class ChangedFilesInput(BaseModel):
    """è·å–å˜æ›´æ–‡ä»¶çš„è¾“å…¥"""
    base_commit: str = Field(description="åŸºå‡† commit å“ˆå¸Œ")
    new_commit: str = Field(description="æ–° commit å“ˆå¸Œ")


class GetChangedFilesTool(BaseTool):
    """è·å–å˜æ›´æ–‡ä»¶åˆ—è¡¨å·¥å…·"""
    name: str = "get_changed_files"
    description: str = "è·å–ä¸¤ä¸ª commit ä¹‹é—´å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨ã€‚å¿«é€Ÿäº†è§£å˜æ›´èŒƒå›´æ—¶ä½¿ç”¨ã€‚"
    args_schema: Type[BaseModel] = ChangedFilesInput
    
    git_tools: GitTools = Field(default=None, exclude=True)
    
    def _run(self, base_commit: str, new_commit: str) -> str:
        result = self.git_tools.get_changed_files(base_commit, new_commit)
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)


class GetChangedFilesDetailedTool(BaseTool):
    """è·å–è¯¦ç»†å˜æ›´ä¿¡æ¯å·¥å…·"""
    name: str = "get_changed_files_detailed"
    description: str = """è·å–è¯¦ç»†çš„æ–‡ä»¶å˜æ›´ä¿¡æ¯ï¼ŒåŒ…æ‹¬å˜æ›´ç±»å‹ã€è¡Œæ•°ç»Ÿè®¡å’Œ hunk ä¿¡æ¯ã€‚
    
è¿”å›æ ¼å¼åŒ…å«ï¼š
- path: æ–‡ä»¶è·¯å¾„
- changeType: å˜æ›´ç±»å‹ï¼ˆADD/MODIFY/DELETEï¼‰
- hunks: å˜æ›´è¡Œå—ï¼ŒåŒ…å« oldStart, oldLines, newStart, newLines
- additions/deletions: æ–°å¢/åˆ é™¤è¡Œæ•°ç»Ÿè®¡

è¿™ä¸ªå·¥å…·çš„è¾“å‡ºå¯ä»¥ç›´æ¥ä¼ é€’ç»™ map_hunks_to_symbols è¿›è¡Œå½±å“åˆ†æã€‚"""
    args_schema: Type[BaseModel] = ChangedFilesInput
    
    git_tools: GitTools = Field(default=None, exclude=True)
    
    def _run(self, base_commit: str, new_commit: str) -> str:
        import json
        result = self.git_tools.get_changed_files_detailed(base_commit, new_commit)
        
        # è½¬æ¢ä¸ºç¬¦åˆåç«¯ API çš„æ ¼å¼
        normalized_result = []
        for item in result:
            if "error" in item:
                continue
                
            # ç¡®å®šæ–‡ä»¶è·¯å¾„
            path = item.get("b_path") or item.get("a_path") or "unknown"
            
            # è½¬æ¢å˜æ›´ç±»å‹
            change_type_map = {
                "A": "ADD",
                "D": "DELETE",
                "M": "MODIFY",
                "R": "RENAME"
            }
            change_type = change_type_map.get(item.get("change_type", "M"), "MODIFY")
            
            normalized = {
                "path": path,
                "changeType": change_type,
                "hunks": item.get("hunks", []),
                "additions": item.get("additions", 0),
                "deletions": item.get("deletions", 0)
            }
            
            normalized_result.append(normalized)
        
        return json.dumps(normalized_result, ensure_ascii=False, indent=2)


class FileDiffInput(BaseModel):
    """è·å–æ–‡ä»¶ diff çš„è¾“å…¥"""
    base_commit: str = Field(description="åŸºå‡† commit å“ˆå¸Œ")
    new_commit: str = Field(description="æ–° commit å“ˆå¸Œ")
    file_path: str = Field(description="æ–‡ä»¶è·¯å¾„")
    offset: int = Field(default=0, description="èµ·å§‹è¡Œå·ï¼ˆä»0å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†æ®µè¯»å–å¤§ diff")
    limit: int = Field(default=300, description="è¯»å–çš„è¡Œæ•°ã€‚é»˜è®¤300è¡Œï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´")


class GetFileDiffTool(BaseTool):
    """è·å–æ–‡ä»¶ diff å·¥å…·"""
    name: str = "get_file_diff"
    description: str = """è·å–ç‰¹å®šæ–‡ä»¶åœ¨ä¸¤ä¸ª commit ä¹‹é—´çš„ diff å†…å®¹ï¼ˆå˜æ›´éƒ¨åˆ†ï¼‰ã€‚æ”¯æŒåˆ†æ®µè¯»å–å¤§ diffã€‚

âš ï¸ é‡è¦åŒºåˆ«ï¼š
- âŒ ä¸æ˜¯è¯»å–å®Œæ•´æ–‡ä»¶å†…å®¹ï¼ˆé‚£æ˜¯ read_file æˆ– get_file_content_by_commitï¼‰
- âœ… åªè¿”å›ä¸¤ä¸ªç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ï¼ˆdiffï¼‰ï¼Œé€šå¸¸æ¯”å®Œæ•´æ–‡ä»¶å°å¾—å¤š
- âœ… diff çš„æ€»è¡Œæ•° â‰  æ–‡ä»¶çš„æ€»è¡Œæ•°

ğŸ“– ä½¿ç”¨æ–¹å¼ï¼š
- **å° diff (<300è¡Œ)**: ç›´æ¥è°ƒç”¨ get_file_diff(base, new, path) å³å¯
- **å¤§ diff (>300è¡Œ)**: åˆ†æ®µè¯»å–
  * ç¬¬1æ®µ: get_file_diff(base, new, path, offset=0, limit=300)
  * ç¬¬2æ®µ: get_file_diff(base, new, path, offset=300, limit=300)
  * ç»§ç»­è°ƒç”¨ç›´åˆ°è¯»å®Œ
  * âš ï¸ offset å¿…é¡»åŸºäº diff çš„æ€»è¡Œæ•°ï¼Œä¸æ˜¯æ–‡ä»¶çš„æ€»è¡Œæ•°ï¼

ğŸ’¡ å·¥å…·ä¼šåœ¨è¾“å‡ºæœ«å°¾æ˜¾ç¤º diff æ€»è¡Œæ•°å’Œå½“å‰è¯»å–èŒƒå›´ï¼Œæ–¹ä¾¿åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è¯»å–

ğŸ“Œ å…¸å‹åœºæ™¯ï¼š
- âœ… æŸ¥çœ‹æŸä¸ªæ–‡ä»¶åœ¨ä¸¤ä¸ª commit ä¹‹é—´æ”¹äº†ä»€ä¹ˆ
- âŒ ä¸è¦ç”¨äºè¯»å–æ–‡ä»¶çš„å®Œæ•´å†…å®¹"""
    args_schema: Type[BaseModel] = FileDiffInput
    
    git_tools: GitTools = Field(default=None, exclude=True)
    
    def _run(self, base_commit: str, new_commit: str, file_path: str, offset: int = 0, limit: int = 300) -> str:
        # ç›´æ¥è°ƒç”¨åº•å±‚æ–¹æ³•ï¼Œæ‰€æœ‰åˆ†æ®µé€»è¾‘å·²åœ¨åº•å±‚å®ç°
        return self.git_tools.get_file_diff(base_commit, new_commit, file_path, offset, limit)


class FileContentInput(BaseModel):
    """è·å–æ–‡ä»¶å†…å®¹çš„è¾“å…¥"""
    commit_hash: str = Field(description="commit å“ˆå¸Œ")
    file_path: str = Field(description="æ–‡ä»¶è·¯å¾„")
    offset: int = Field(default=0, description="èµ·å§‹è¡Œå·ï¼ˆä»0å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†æ®µè¯»å–å¤§æ–‡ä»¶")
    limit: int = Field(default=500, description="è¯»å–çš„è¡Œæ•°ã€‚é»˜è®¤500è¡Œï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´")


class GetFileContentByCommitTool(BaseTool):
    """è·å–æ–‡ä»¶å†…å®¹å·¥å…·"""
    name: str = "get_file_content_by_commit"
    description: str = """è·å–ç‰¹å®š commit ä¸­æŸä¸ªæ–‡ä»¶çš„å†…å®¹ã€‚æ”¯æŒåˆ†æ®µè¯»å–å¤§æ–‡ä»¶ã€‚

ğŸ“– ä½¿ç”¨æ–¹å¼ï¼š
- **å°æ–‡ä»¶ (<500è¡Œ)**: ç›´æ¥è°ƒç”¨ get_file_content_by_commit(commit, path) å³å¯
- **å¤§æ–‡ä»¶ (>500è¡Œ)**: åˆ†æ®µè¯»å–
  * ç¬¬1æ®µ: get_file_content_by_commit(commit, path, offset=0, limit=500)
  * ç¬¬2æ®µ: get_file_content_by_commit(commit, path, offset=500, limit=500)
  * ç»§ç»­è°ƒç”¨ç›´åˆ°è¯»å®Œ

âš ï¸ å¤§æ–‡ä»¶å¤„ç†å»ºè®®ï¼š
- ä¼˜å…ˆä½¿ç”¨ get_file_diff æŸ¥çœ‹å˜æ›´éƒ¨åˆ†ï¼ˆæœ€é«˜æ•ˆï¼‰
- æˆ–ä½¿ç”¨ search_in_file æœç´¢å…³é”®å†…å®¹
- åªåœ¨å¿…é¡»äº†è§£å®Œæ•´æ–‡ä»¶æ—¶æ‰åˆ†æ®µè¯»å–å…¨æ–‡

ğŸ’¡ å·¥å…·ä¼šåœ¨è¾“å‡ºæœ«å°¾æ˜¾ç¤ºæ–‡ä»¶æ€»è¡Œæ•°å’Œå½“å‰è¯»å–èŒƒå›´ï¼Œæ–¹ä¾¿åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è¯»å–"""
    args_schema: Type[BaseModel] = FileContentInput
    
    git_tools: GitTools = Field(default=None, exclude=True)
    
    def _run(self, commit_hash: str, file_path: str, offset: int = 0, limit: int = 500) -> str:
        # ç›´æ¥è°ƒç”¨åº•å±‚æ–¹æ³•ï¼Œæ‰€æœ‰åˆ†æ®µé€»è¾‘å·²åœ¨åº•å±‚å®ç°
        return self.git_tools.get_file_content_by_commit(commit_hash, file_path, offset, limit)


class CommitsBetweenInput(BaseModel):
    """è·å–æäº¤å†å²çš„è¾“å…¥"""
    base_commit: str = Field(description="åŸºå‡† commit å“ˆå¸Œ")
    new_commit: str = Field(description="æ–° commit å“ˆå¸Œ")
    max_count: int = Field(
        default=20, 
        description="""æœ€å¤šè¿”å›çš„ commit æ•°é‡ã€‚å»ºè®®æ ¹æ®æ—¶é—´è·¨åº¦è°ƒæ•´ï¼š
        - å°å‹å˜æ›´ï¼ˆ<1å‘¨ï¼‰: 10-15 ä¸ª
        - ä¸­å‹å˜æ›´ï¼ˆ1-2å‘¨ï¼‰: 20-30 ä¸ª [é»˜è®¤]
        - å¤§å‹å˜æ›´ï¼ˆ>1æœˆï¼‰: 50-100 ä¸ª
        åˆç†è®¾ç½®å¯ä»¥å®Œæ•´äº†è§£æ¼”è¿›å†å²è€Œä¸é—æ¼å…³é”®ä¿¡æ¯ã€‚
        å¦‚æœä¸ç¡®å®šï¼Œå¯ä»¥å…ˆç”¨é»˜è®¤å€¼ï¼Œæ ¹æ®è¿”å›ç»“æœåˆ¤æ–­æ˜¯å¦éœ€è¦å¢å¤§"""
    )


class GetCommitsBetweenTool(BaseTool):
    """è·å–æäº¤å†å²å·¥å…·"""
    name: str = "get_commits_between"
    description: str = """è·å–ä¸¤ä¸ª commit ä¹‹é—´çš„æ‰€æœ‰æäº¤å†å²ã€‚äº†è§£å˜æ›´æ¼”è¿›è¿‡ç¨‹æ—¶ä½¿ç”¨ã€‚

ğŸ“– ä½¿ç”¨å»ºè®®ï¼š
- å…ˆç”¨é»˜è®¤ max_count=20 è·å–ï¼Œè§‚å¯Ÿæ—¶é—´è·¨åº¦
- å¦‚æœè¿”å›çš„ commit æ•°é‡ç­‰äº max_countï¼Œè¯´æ˜å¯èƒ½è¿˜æœ‰æ›´å¤š commit æœªè·å–
- æ ¹æ®ä¸¤ä¸ª commit çš„æ—¥æœŸå·®å¼‚ï¼Œé€‚å½“å¢å¤§ max_count

ğŸ’¡ å·¥å…·ä¼šåœ¨è¾“å‡ºæœ«å°¾æ˜¾ç¤ºå®é™…è¿”å›çš„ commit æ•°é‡å’Œæ—¶é—´è·¨åº¦ä¿¡æ¯"""
    args_schema: Type[BaseModel] = CommitsBetweenInput
    
    git_tools: GitTools = Field(default=None, exclude=True)
    
    def _run(self, base_commit: str, new_commit: str, max_count: int = 20) -> str:
        result = self.git_tools.get_commits_between(base_commit, new_commit, max_count)
        import json
        
        # æ·»åŠ å…ƒä¿¡æ¯åé¦ˆ
        if isinstance(result, list) and len(result) > 0:
            actual_count = len(result)
            
            # è·å–æ—¶é—´è·¨åº¦
            first_date = result[0].get('date', '') if result else ''
            last_date = result[-1].get('date', '') if result else ''
            
            meta_info = f"\n\n{'='*70}\n"
            meta_info += f"ğŸ“Š è·å–åˆ° {actual_count} ä¸ª commit\n"
            meta_info += f"ğŸ“… æ—¶é—´èŒƒå›´: {last_date} â†’ {first_date}\n"
            
            # åˆ¤æ–­æ˜¯å¦å¯èƒ½æœ‰æ›´å¤š commit
            if actual_count == max_count:
                meta_info += f"âš ï¸  è¿”å›æ•°é‡è¾¾åˆ°ä¸Šé™ ({max_count})ï¼Œå¯èƒ½è¿˜æœ‰æ›´å¤š commit æœªè·å–\n"
                meta_info += f"ğŸ’¡ å¦‚éœ€è·å–å®Œæ•´å†å²ï¼Œè¯·å¢å¤§ max_countï¼Œå»ºè®®:\n"
                meta_info += f"   get_commits_between('{base_commit}', '{new_commit}', max_count={max_count * 2})\n"
            else:
                meta_info += f"âœ… å·²è·å–å®Œæ•´æäº¤å†å²\n"
            
            meta_info += f"{'='*70}\n"
            
            return json.dumps(result, ensure_ascii=False, indent=2) + meta_info
        else:
            return json.dumps(result, ensure_ascii=False, indent=2)


# ============================================
# æºç åˆ†æ API å·¥å…·çš„ LangChain å°è£…
# ============================================

class IndexProjectInput(BaseModel):
    """ç´¢å¼•é¡¹ç›®çš„è¾“å…¥"""
    repo_path: str = Field(description="é¡¹ç›®æ ¹è·¯å¾„")


class IndexProjectTool(BaseTool):
    """ç´¢å¼•é¡¹ç›®å·¥å…·"""
    name: str = "index_project"
    description: str = "ç´¢å¼• Java é¡¹ç›®ï¼Œæ„å»ºè°ƒç”¨å›¾ã€‚è¿™æ˜¯ä½¿ç”¨æºç åˆ†æåŠŸèƒ½çš„ç¬¬ä¸€æ­¥ï¼Œå¿…é¡»å…ˆç´¢å¼•æ‰èƒ½è¿›è¡Œåç»­åˆ†æã€‚"
    args_schema: Type[BaseModel] = IndexProjectInput
    
    api_tools: AnalyzerAPITools = Field(default=None, exclude=True)
    
    def _run(self, repo_path: str) -> str:
        result = self.api_tools.index_project(repo_path)
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)


class GetIndexStatusTool(BaseTool):
    """è·å–ç´¢å¼•çŠ¶æ€å·¥å…·"""
    name: str = "get_index_status"
    description: str = "æŸ¥è¯¢é¡¹ç›®ç´¢å¼•çŠ¶æ€ï¼Œç¡®è®¤æ˜¯å¦å·²ç´¢å¼•å®Œæˆã€‚"
    
    api_tools: AnalyzerAPITools = Field(default=None, exclude=True)
    
    def _run(self) -> str:
        result = self.api_tools.get_index_status()
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)
    
    async def _arun(self) -> str:
        return self._run()


class MapHunksInput(BaseModel):
    """æ˜ å°„å˜æ›´åˆ°ç¬¦å·çš„è¾“å…¥"""
    changes: str = Field(
        description="""æ–‡ä»¶å˜æ›´åˆ—è¡¨çš„ JSON å­—ç¬¦ä¸²ã€‚æ¯é¡¹å¿…é¡»åŒ…å«:
- path: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
- changeType: å˜æ›´ç±»å‹ï¼ˆADD/MODIFY/DELETE/RENAMEï¼‰
- hunks: å˜æ›´è¡Œå—åˆ—è¡¨ï¼Œæ¯ä¸ª hunk åŒ…å«ï¼š
  * oldStart: æ—§æ–‡ä»¶èµ·å§‹è¡Œå·
  * oldLines: æ—§æ–‡ä»¶è¡Œæ•°
  * newStart: æ–°æ–‡ä»¶èµ·å§‹è¡Œå·
  * newLines: æ–°æ–‡ä»¶è¡Œæ•°

ç¤ºä¾‹æ ¼å¼ï¼š
[{
  "path": "src/main/java/Example.java",
  "changeType": "MODIFY",
  "hunks": [{"oldStart": 10, "oldLines": 5, "newStart": 10, "newLines": 8}]
}]"""
    )


class MapHunksToSymbolsTool(BaseTool):
    """æ˜ å°„å˜æ›´åˆ°ç¬¦å·å·¥å…·"""
    name: str = "map_hunks_to_symbols"
    description: str = """å°†æ–‡ä»¶å˜æ›´æ˜ å°„åˆ°å—å½±å“çš„å…·ä½“æ–¹æ³•å’Œç±»ã€‚ç”¨äºç²¾ç¡®è¯†åˆ«å˜æ›´å½±å“çš„ä»£ç ç¬¦å·ã€‚

IMPORTANT: è¾“å…¥å¿…é¡»æ˜¯æ­£ç¡®çš„æ ¼å¼ï¼ŒåŒ…å« path, changeType, hunks å­—æ®µã€‚
hunks å¿…é¡»æ˜¯æ ‡å‡† Git diff æ ¼å¼ï¼šoldStart, oldLines, newStart, newLinesã€‚

é€šå¸¸ä» get_file_diff è·å– diff å†…å®¹åï¼Œè§£æå‡º hunk ä¿¡æ¯å†è°ƒç”¨æ­¤å·¥å…·ã€‚"""
    args_schema: Type[BaseModel] = MapHunksInput
    
    api_tools: AnalyzerAPITools = Field(default=None, exclude=True)
    
    def _run(self, changes: str) -> str:
        import json
        try:
            changes_list = json.loads(changes)
        except:
            # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
            changes_list = changes
        
        # è½¬æ¢æ•°æ®æ ¼å¼ï¼šå°† AI å¯èƒ½ç”Ÿæˆçš„ç®€åŒ–æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        normalized_changes = []
        for change in changes_list:
            normalized = {
                "path": change.get("path", ""),
                "changeType": change.get("changeType", "MODIFY"),
                "hunks": []
            }
            
            # å¤„ç† hunks æ ¼å¼è½¬æ¢
            hunks = change.get("hunks", [])
            for hunk in hunks:
                if isinstance(hunk, dict):
                    # å¦‚æœæ˜¯ç®€åŒ–æ ¼å¼ï¼ˆstartLine, endLineï¼‰ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    if "startLine" in hunk and "endLine" in hunk:
                        start_line = hunk["startLine"]
                        end_line = hunk["endLine"]
                        line_count = max(1, end_line - start_line + 1)
                        normalized_hunk = {
                            "oldStart": start_line,
                            "oldLines": line_count,
                            "newStart": start_line,
                            "newLines": line_count
                        }
                    # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œä¿æŒä¸å˜
                    elif "newStart" in hunk and "newLines" in hunk:
                        normalized_hunk = hunk
                    else:
                        # å¦‚æœæ ¼å¼æ— æ³•è¯†åˆ«ï¼Œè·³è¿‡
                        continue
                    
                    normalized["hunks"].append(normalized_hunk)
            
            # å¦‚æœæ²¡æœ‰ hunksï¼Œæ·»åŠ ä¸€ä¸ªè¦†ç›–æ•´ä¸ªæ–‡ä»¶çš„ hunkï¼ˆé»˜è®¤å‰ 1000 è¡Œï¼‰
            if not normalized["hunks"]:
                normalized["hunks"].append({
                    "oldStart": 1,
                    "oldLines": 1000,
                    "newStart": 1,
                    "newLines": 1000
                })
            
            normalized_changes.append(normalized)
        
        result = self.api_tools.map_hunks_to_symbols(normalized_changes)
        return json.dumps(result, ensure_ascii=False, indent=2)


class AnalyzeImpactInput(BaseModel):
    """å½±å“åˆ†æçš„è¾“å…¥"""
    seeds: str = Field(description="""ç§å­æ–¹æ³•/ç±»çš„ JSON å­—ç¬¦ä¸²ã€‚
æ ¼å¼ï¼š{"methods": [{"fqnClass": "å®Œæ•´ç±»å", "methodName": "æ–¹æ³•å", "paramTypes": ["å‚æ•°ç±»å‹"]}], "classes": ["å®Œæ•´ç±»å"]}
æ³¨æ„ï¼šç±»åå¿…é¡»ä½¿ç”¨å®Œæ•´åŒ…åï¼ˆFQNï¼‰ï¼Œä¾‹å¦‚ "com.example.MyClass" è€Œä¸æ˜¯ "MyClass"ã€‚
æ–¹æ³•å¿…é¡»åŒ…å« fqnClassï¼ˆå®Œæ•´ç±»åï¼‰ã€methodNameï¼ˆæ–¹æ³•åï¼‰ã€paramTypesï¼ˆå‚æ•°ç±»å‹åˆ—è¡¨ï¼‰ã€‚""")
    depth: int = Field(default=2, description="ä¼ æ’­æ·±åº¦ï¼Œå»ºè®® 1-5")
    direction: str = Field(default="both", description="ä¼ æ’­æ–¹å‘ï¼šinboundï¼ˆå‘ä¸Šæ‰¾è°ƒç”¨è€…ï¼‰ã€outboundï¼ˆå‘ä¸‹æ‰¾å½±å“ï¼‰ã€bothï¼ˆåŒå‘ï¼‰")
    include_edges: bool = Field(default=True, description="æ˜¯å¦è¿”å›è°ƒç”¨è¾¹ä¿¡æ¯")


class AnalyzeImpactTool(BaseTool):
    """å½±å“åˆ†æå·¥å…·"""
    name: str = "analyze_impact"
    description: str = """åˆ†æå˜æ›´çš„å½±å“èŒƒå›´ã€‚åŸºäºè°ƒç”¨å›¾è¿›è¡Œä¼ æ’­åˆ†æï¼Œæ‰¾å‡ºå—å½±å“çš„æ–¹æ³•ã€‚
é‡è¦ï¼šseeds å‚æ•°ä¸­çš„ç±»åå¿…é¡»ä½¿ç”¨å®Œæ•´åŒ…åï¼ˆå¦‚ com.example.MyClassï¼‰ï¼Œä¸èƒ½åªç”¨ç®€å•ç±»åï¼ˆMyClassï¼‰ã€‚
å»ºè®®å…ˆä½¿ç”¨ map_hunks_to_symbols å·¥å…·è·å–å—å½±å“çš„æ–¹æ³•å’Œç±»ï¼ˆä¼šåŒ…å«å®Œæ•´ç±»åï¼‰ï¼Œå†å°†å…¶ç»“æœä½œä¸º seeds ä¼ å…¥æœ¬å·¥å…·ã€‚
æ”¯æŒå‘ä¸Šï¼ˆæ‰¾è°ƒç”¨è€…/æµ‹è¯•å…¥å£ï¼‰ã€å‘ä¸‹ï¼ˆæ‰¾è¢«è°ƒç”¨/å½±å“èŒƒå›´ï¼‰ã€åŒå‘ä¼ æ’­ã€‚"""
    args_schema: Type[BaseModel] = AnalyzeImpactInput
    
    api_tools: AnalyzerAPITools = Field(default=None, exclude=True)
    
    def _run(self, seeds: str, depth: int = 2, direction: str = "both", include_edges: bool = True) -> str:
        import json
        try:
            seeds_dict = json.loads(seeds)
        except:
            seeds_dict = seeds
        
        result = self.api_tools.analyze_impact(seeds_dict, depth, direction, include_edges)
        return json.dumps(result, ensure_ascii=False, indent=2)


# ============================================
# æºç è¯»å–å·¥å…·çš„ LangChain å°è£…
# ============================================

class ReadFileInput(BaseModel):
    """è¯»å–æ–‡ä»¶çš„è¾“å…¥"""
    relative_path: str = Field(description="ç›¸å¯¹äºé¡¹ç›®æ ¹çš„æ–‡ä»¶è·¯å¾„")
    max_lines: int = Field(default=500, description="æ¯æ¬¡è¯»å–çš„æœ€å¤§è¡Œæ•°ï¼Œé»˜è®¤ 500 è¡Œ")
    offset: int = Field(default=0, description="èµ·å§‹è¡Œå·ï¼ˆä» 0 å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†æ®µè¯»å–å¤§æ–‡ä»¶")


class ReadFileTool(BaseTool):
    """è¯»å–æ–‡ä»¶å·¥å…·"""
    name: str = "read_file"
    description: str = """è¯»å–é¡¹ç›®ä¸­çš„æ–‡ä»¶å†…å®¹ã€‚æ”¯æŒåˆ†æ®µè¯»å–å¤§æ–‡ä»¶ã€‚

âš ï¸ é‡è¦é™åˆ¶ï¼š
- âŒ åªèƒ½è¯»å–æ–‡ä»¶ï¼Œä¸èƒ½è¯»å–ç›®å½•
- âŒ è¦åˆ—å‡ºç›®å½•å†…å®¹ï¼Œè¯·ä½¿ç”¨ list_directory å·¥å…·
- âŒ è¦æŸ¥æ‰¾æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ find_file å·¥å…·

ğŸ“– ä½¿ç”¨æ–¹å¼ï¼š
- **å°æ–‡ä»¶ (<500è¡Œ)**: ç›´æ¥è°ƒç”¨ read_file(path) å³å¯
- **å¤§æ–‡ä»¶ (>500è¡Œ)**: åˆ†æ®µè¯»å–
  * ç¬¬1æ®µ: read_file(path, offset=0, max_lines=500)
  * ç¬¬2æ®µ: read_file(path, offset=500, max_lines=500)
  * ç»§ç»­è°ƒç”¨ç›´åˆ°è¯»å®Œ

ğŸ’¡ å·¥å…·ä¼šåœ¨è¾“å‡ºæœ«å°¾æ˜¾ç¤ºæ–‡ä»¶æ€»è¡Œæ•°å’Œå½“å‰è¯»å–èŒƒå›´ï¼Œæ–¹ä¾¿åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è¯»å–

âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼š
- å¤§æ–‡ä»¶ä¼šæ¶ˆè€—å¤§é‡ token å’Œæ—¶é—´ï¼Œå½±å“æ‰§è¡Œæ•ˆç‡
- å¯¹äºä»£ç å˜æ›´åˆ†æï¼Œä¼˜å…ˆä½¿ç”¨ get_file_diff æŸ¥çœ‹å…·ä½“æ”¹åŠ¨
- å¦‚æœåªéœ€æŸ¥æ‰¾ç‰¹å®šå†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨ search_in_file
- åªåœ¨éœ€è¦ç†è§£å®Œæ•´æ–‡ä»¶ä¸Šä¸‹æ–‡æ—¶ä½¿ç”¨æœ¬å·¥å…·

é€‚ç”¨åœºæ™¯ï¼š
âœ… READMEã€é…ç½®æ–‡ä»¶ç­‰å°æ–‡æ¡£ï¼ˆé€šå¸¸ <5KBï¼Œ<500è¡Œï¼‰
âœ… éœ€è¦ç†è§£å®Œæ•´ä»£ç é€»è¾‘å’Œä¸Šä¸‹æ–‡
âŒ å¤§å‹æºç æ–‡ä»¶ï¼ˆå»ºè®®å…ˆç”¨ get_file_diff æˆ– search_in_fileï¼‰
âŒ åªæƒ³æŸ¥çœ‹ä»£ç å˜æ›´ï¼ˆåº”è¯¥ç”¨ get_file_diffï¼‰
âŒ æŸ¥çœ‹ç›®å½•æœ‰å“ªäº›æ–‡ä»¶ï¼ˆåº”è¯¥ç”¨ list_directoryï¼‰"""
    args_schema: Type[BaseModel] = ReadFileInput
    
    source_tools: SourceCodeTools = Field(default=None, exclude=True)
    
    def _run(self, relative_path: str, max_lines: int = 500, offset: int = 0) -> str:
        result = self.source_tools.read_file(relative_path, max_lines, offset)
        return result


class SearchInFileInput(BaseModel):
    """æœç´¢æ–‡ä»¶çš„è¾“å…¥"""
    relative_path: str = Field(description="æ–‡ä»¶è·¯å¾„")
    keyword: str = Field(description="æœç´¢å…³é”®å­—")


class SearchInFileTool(BaseTool):
    """æœç´¢æ–‡ä»¶å·¥å…·"""
    name: str = "search_in_file"
    description: str = """åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢å…³é”®å­—ã€‚

âš ï¸ é‡è¦é™åˆ¶ï¼š
- âŒ åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢ï¼Œä¸æ˜¯æœç´¢æ–‡ä»¶å
- âŒ è¦æŸ¥æ‰¾æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ find_file å·¥å…·
- âŒ è¦åˆ—å‡ºç›®å½•å†…å®¹ï¼Œè¯·ä½¿ç”¨ list_directory å·¥å…·

âœ… é€‚ç”¨åœºæ™¯ï¼š
- åœ¨å·²çŸ¥æ–‡ä»¶ä¸­æŸ¥æ‰¾ç‰¹å®šæ–¹æ³•ã€ç±»æˆ–å˜é‡
- æŸ¥æ‰¾åŒ…å«ç‰¹å®šå…³é”®å­—çš„ä»£ç è¡Œ
- å®šä½æŸä¸ªå­—ç¬¦ä¸²åœ¨æ–‡ä»¶ä¸­çš„ä½ç½®

ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š
- search_in_file("src/Main.java", "public static void")
- search_in_file("pom.xml", "spring-boot")"""
    args_schema: Type[BaseModel] = SearchInFileInput
    
    source_tools: SourceCodeTools = Field(default=None, exclude=True)
    
    def _run(self, relative_path: str, keyword: str) -> str:
        result = self.source_tools.search_in_file(relative_path, keyword)
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)


class ListJavaFilesInput(BaseModel):
    """åˆ—å‡º Java æ–‡ä»¶çš„è¾“å…¥"""
    directory: str = Field(default="", description="ç›¸å¯¹ç›®å½•è·¯å¾„ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ ¹ç›®å½•")


class ListJavaFilesTool(BaseTool):
    """åˆ—å‡º Java æ–‡ä»¶å·¥å…·"""
    name: str = "list_java_files"
    description: str = "åˆ—å‡ºç›®å½•ä¸‹çš„æ‰€æœ‰ Java æ–‡ä»¶ã€‚è¿”å›æŒ‰ç›®å½•åˆ†ç»„çš„ç»Ÿè®¡ä¿¡æ¯å’Œå®Œæ•´æ–‡ä»¶åˆ—è¡¨ã€‚"
    args_schema: Type[BaseModel] = ListJavaFilesInput
    
    source_tools: SourceCodeTools = Field(default=None, exclude=True)
    
    def _run(self, directory: str = "") -> str:
        result = self.source_tools.list_java_files(directory)
        import json
        from collections import defaultdict
        
        # æŒ‰ç›®å½•åˆ†ç»„ç»Ÿè®¡
        dir_stats = defaultdict(list)
        for file_path in result:
            if isinstance(file_path, str) and not file_path.startswith("Error"):
                # æå–ç›®å½•è·¯å¾„ï¼ˆå»æ‰æ–‡ä»¶åï¼‰
                parts = file_path.split('/')
                if len(parts) > 1:
                    dir_path = '/'.join(parts[:-1])
                    dir_stats[dir_path].append(parts[-1])
                else:
                    dir_stats['æ ¹ç›®å½•'].append(file_path)
        
        # æ„å»ºè¾“å‡ºç»“æ„
        output = {
            "æ€»è®¡": len(result),
            "ç›®å½•ç»Ÿè®¡": {
                dir_path: {
                    "æ–‡ä»¶æ•°": len(files),
                    "æ–‡ä»¶åˆ—è¡¨": sorted(files)
                }
                for dir_path, files in sorted(dir_stats.items())
            }
        }
        
        return json.dumps(output, ensure_ascii=False, indent=2)


class ListDirectoryInput(BaseModel):
    """åˆ—å‡ºç›®å½•å†…å®¹çš„è¾“å…¥"""
    directory: str = Field(default="", description="ç›¸å¯¹ç›®å½•è·¯å¾„ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé¡¹ç›®æ ¹ç›®å½•")


class ListDirectoryTool(BaseTool):
    """åˆ—å‡ºç›®å½•å†…å®¹å·¥å…·"""
    name: str = "list_directory"
    description: str = """åˆ—å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶å’Œå­ç›®å½•ã€‚
    
ğŸ“ ç”¨é€”ï¼š
- æŸ¥çœ‹é¡¹ç›®æ ¹ç›®å½•æœ‰å“ªäº›æ–‡ä»¶ï¼ˆå¦‚æ„å»ºæ–‡ä»¶ã€é…ç½®æ–‡ä»¶ï¼‰
- æµè§ˆæŸä¸ªåŒ…ä¸‹çš„ç›®å½•ç»“æ„
- äº†è§£é¡¹ç›®ç»„ç»‡æ–¹å¼

ğŸ“– ä½¿ç”¨ç¤ºä¾‹ï¼š
- list_directory("") â†’ åˆ—å‡ºé¡¹ç›®æ ¹ç›®å½•
- list_directory("src/main/java") â†’ åˆ—å‡º Java æºç ç›®å½•
- list_directory("docs") â†’ åˆ—å‡ºæ–‡æ¡£ç›®å½•

ğŸ’¡ æç¤ºï¼š
- åªåˆ—å‡ºç›´æ¥å­é¡¹ï¼Œä¸é€’å½’
- ç›®å½•ä»¥ / ç»“å°¾æ ‡è¯†
- æ˜¾ç¤ºæ–‡ä»¶å¤§å°"""
    args_schema: Type[BaseModel] = ListDirectoryInput
    
    source_tools: SourceCodeTools = Field(default=None, exclude=True)
    
    def _run(self, directory: str = "") -> str:
        result = self.source_tools.list_directory(directory)
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)


class FindFileInput(BaseModel):
    """æŸ¥æ‰¾æ–‡ä»¶çš„è¾“å…¥"""
    pattern: str = Field(description="æ–‡ä»¶åæ¨¡å¼ï¼Œæ”¯æŒé€šé…ç¬¦ã€‚ä¾‹å¦‚: 'pom.xml', '*.xml', '**/*.properties'")
    max_results: int = Field(default=20, description="æœ€å¤šè¿”å›çš„ç»“æœæ•°ï¼Œé»˜è®¤ 20")


class FindFileTool(BaseTool):
    """æŸ¥æ‰¾æ–‡ä»¶å·¥å…·"""
    name: str = "find_file"
    description: str = """åœ¨é¡¹ç›®ä¸­æŸ¥æ‰¾ç‰¹å®šæ–‡ä»¶åã€‚
    
ğŸ” ç”¨é€”ï¼š
- æŸ¥æ‰¾æ„å»ºæ–‡ä»¶ï¼ˆå¦‚ pom.xml, build.gradle, package.jsonï¼‰
- æŸ¥æ‰¾é…ç½®æ–‡ä»¶ï¼ˆå¦‚ application.properties, config.yml, .gitignoreï¼‰
- æŸ¥æ‰¾æ–‡æ¡£ï¼ˆå¦‚ README.md, CHANGELOG.mdï¼‰
- æŸ¥æ‰¾ç‰¹å®šæ‰©å±•åçš„æ–‡ä»¶

ğŸ“– ä½¿ç”¨ç¤ºä¾‹ï¼š
- find_file("pom.xml") â†’ æŸ¥æ‰¾ç²¾ç¡®æ–‡ä»¶å
- find_file("*.xml") â†’ æŸ¥æ‰¾æ‰€æœ‰ XML æ–‡ä»¶
- find_file("README*") â†’ æŸ¥æ‰¾æ‰€æœ‰ README æ–‡ä»¶
- find_file("*.properties") â†’ æŸ¥æ‰¾æ‰€æœ‰ properties æ–‡ä»¶

ğŸ’¡ æç¤ºï¼š
- æ”¯æŒé€šé…ç¬¦ * å’Œ ?
- é€’å½’æœç´¢æ•´ä¸ªé¡¹ç›®
- é»˜è®¤æœ€å¤šè¿”å› 20 ä¸ªç»“æœ"""
    args_schema: Type[BaseModel] = FindFileInput
    
    source_tools: SourceCodeTools = Field(default=None, exclude=True)
    
    def _run(self, pattern: str, max_results: int = 20) -> str:
        result = self.source_tools.find_file(pattern, max_results)
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)


# ============================================
# å·¥å…·åˆ›å»ºå‡½æ•°
# ============================================

def create_langchain_tools(
    repo_path: str,
    api_base_url: str = "http://localhost:8089"
) -> List[BaseTool]:
    """
    åˆ›å»ºæ‰€æœ‰ LangChain å·¥å…·ã€‚
    
    Args:
        repo_path: é¡¹ç›®è·¯å¾„
        api_base_url: API åŸºç¡€ URL
        
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    from .tools import get_all_tools
    
    tools_instances = get_all_tools(repo_path, api_base_url)
    git = tools_instances["git"]
    api = tools_instances["api"]
    source = tools_instances["source"]
    
    tools = [
        # Git å·¥å…·
        GetCommitInfoTool(git_tools=git),
        GetChangedFilesTool(git_tools=git),
        GetChangedFilesDetailedTool(git_tools=git),
        GetFileDiffTool(git_tools=git),
        GetFileContentByCommitTool(git_tools=git),
        GetCommitsBetweenTool(git_tools=git),
        
        # API å·¥å…·
        IndexProjectTool(api_tools=api),
        GetIndexStatusTool(api_tools=api),
        MapHunksToSymbolsTool(api_tools=api),
        AnalyzeImpactTool(api_tools=api),
        
        # æºç å·¥å…·
        ReadFileTool(source_tools=source),
        SearchInFileTool(source_tools=source),
        ListJavaFilesTool(source_tools=source),
        ListDirectoryTool(source_tools=source),
        FindFileTool(source_tools=source),
    ]
    
    return tools
