"""
å·¥å…·å‡½æ•°é›†åˆï¼šä¾›å¤§æ¨¡å‹è‡ªä¸»è°ƒç”¨çš„å„ç§å·¥å…·ã€‚
åŒ…æ‹¬ Git ä¿¡æ¯æå–å·¥å…·å’Œæºç åˆ†æ REST API å·¥å…·ã€‚
"""

from typing import List, Dict, Any, Optional, Tuple
import subprocess
from git import Repo
import requests
from pathlib import Path


def _paginate_lines(
    lines: List[str],
    offset: int,
    limit: int,
    file_path: str,
    content_type: str = "æ–‡ä»¶"
) -> Tuple[str, str]:
    """
    é€šç”¨çš„è¡Œå†…å®¹åˆ†æ®µå¤„ç†è¾…åŠ©æ–¹æ³•ã€‚
    
    Args:
        lines: æ‰€æœ‰è¡Œçš„åˆ—è¡¨
        offset: èµ·å§‹è¡Œå·ï¼ˆä» 0 å¼€å§‹ï¼‰
        limit: æœ€å¤šè¯»å–çš„è¡Œæ•°
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå…ƒä¿¡æ¯æ˜¾ç¤ºï¼‰
        content_type: å†…å®¹ç±»å‹æè¿°ï¼ˆå¦‚ "æ–‡ä»¶"ã€"Diff"ï¼‰
        
    Returns:
        (åˆ†æ®µå†…å®¹, å…ƒä¿¡æ¯) çš„å…ƒç»„
    """
    total_lines = len(lines)
    
    # æ£€æŸ¥ offset æ˜¯å¦è¶…å‡ºèŒƒå›´
    if offset >= total_lines:
        meta_info = f"\n{'='*70}\n"
        meta_info += f"ğŸ“„ æ–‡ä»¶: {file_path}\n"
        meta_info += f"ğŸ“Š {content_type}æ€»è¡Œæ•°: {total_lines} è¡Œ\n"
        meta_info += f"âŒ é”™è¯¯: offset ({offset}) è¶…å‡ºèŒƒå›´ (æ€»è¡Œæ•°: {total_lines})\n"
        meta_info += f"ğŸ’¡ æç¤º: offset åº”è¯¥åœ¨ 0 åˆ° {total_lines - 1} ä¹‹é—´\n"
        meta_info += f"{'='*70}\n"
        return "", meta_info
    
    # åˆ†æ®µæå–
    end = min(offset + limit, total_lines)
    selected_lines = lines[offset:end]
    content = '\n'.join(selected_lines)
    
    # æ·»åŠ å…ƒä¿¡æ¯
    meta_info = f"\n{'='*70}\n"
    meta_info += f"ğŸ“„ æ–‡ä»¶: {file_path}\n"
    meta_info += f"ğŸ“Š {content_type}æ€»è¡Œæ•°: {total_lines} è¡Œ\n"
    meta_info += f"ğŸ“ å½“å‰è¯»å–èŒƒå›´: ç¬¬ {offset + 1} - {end} è¡Œ\n"
    
    if end < total_lines:
        remaining = total_lines - end
        meta_info += f"âš ï¸  è¿˜æœ‰ {remaining} è¡Œæœªè¯»å–\n"
        meta_info += f"ğŸ’¡ ç»§ç»­è¯»å–è¯·ä½¿ç”¨: offset={end}, limit={limit}\n"
    else:
        meta_info += f"âœ… å·²è¯»å–å®Œæ•´å†…å®¹\n"
    
    meta_info += f"{'='*70}\n"
    
    return content, meta_info


class GitTools:
    """Git ç›¸å…³å·¥å…·å‡½æ•°"""
    
    def __init__(self, repo_path: str):
        self.repo_path = repo_path
        self.repo = Repo(repo_path)
    
    def pull_latest(self, remote: str = "origin", branch: Optional[str] = None, allow_dirty: bool = True):
        """
        æ‹‰å–æœ€æ–°ä»£ç 
        
        Args:
            remote: è¿œç¨‹ä»“åº“åç§°
            branch: è¦æ‹‰å–çš„åˆ†æ”¯
            allow_dirty: æ˜¯å¦å…è®¸æœªæäº¤ä¿®æ”¹
        """
        if self.repo.is_dirty(untracked_files=True) and not allow_dirty:
            raise RuntimeError("ä»“åº“å­˜åœ¨æœªæäº¤ä¿®æ”¹ï¼Œæ”¾å¼ƒè‡ªåŠ¨æ‹‰å–")
        remote_obj = self.repo.remotes[remote]
        remote_obj.fetch()
        if self.repo.head.is_detached and branch is None:
            raise RuntimeError("å½“å‰ä¸º detached HEADï¼Œéœ€æ˜¾å¼æŒ‡å®šè¦æ‹‰å–çš„åˆ†æ”¯")
        target_branch = branch or self.repo.active_branch.name
        remote_obj.pull(target_branch)
    
    def get_commit_info(self, commit_hash: str) -> Dict[str, Any]:
        """
        è·å– commit çš„åŸºæœ¬ä¿¡æ¯ã€‚
        
        Args:
            commit_hash: commit å“ˆå¸Œå€¼
            
        Returns:
            åŒ…å« commit ä¿¡æ¯çš„å­—å…¸
        """
        try:
            commit = self.repo.commit(commit_hash)
            return {
                "hash": commit.hexsha,
                "short_hash": commit.hexsha[:8],
                "author": str(commit.author),
                "email": commit.author.email,
                "date": commit.committed_datetime.isoformat(),
                "message": commit.message.strip(),
                "summary": commit.summary,
                "parents": [p.hexsha for p in commit.parents]
            }
        except Exception as e:
            return {"error": str(e)}
    
    def get_changed_files(self, base_commit: str, new_commit: str) -> List[str]:
        """
        è·å–ä¸¤ä¸ª commit ä¹‹é—´å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨ã€‚
        
        Args:
            base_commit: åŸºå‡† commit
            new_commit: æ–° commit
            
        Returns:
            å˜æ›´æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            base = self.repo.commit(base_commit)
            new = self.repo.commit(new_commit)
            
            diff_index = base.diff(new)
            files = []
            
            for diff in diff_index:
                if diff.a_path:
                    files.append(diff.a_path)
                if diff.b_path and diff.b_path != diff.a_path:
                    files.append(diff.b_path)
            
            return list(set(files))
        except Exception as e:
            return [f"Error: {e}"]
    
    def get_changed_files_detailed(self, base_commit: str, new_commit: str) -> List[Dict[str, Any]]:
        """
        è·å–è¯¦ç»†çš„æ–‡ä»¶å˜æ›´ä¿¡æ¯ï¼ŒåŒ…æ‹¬å˜æ›´ç±»å‹ã€è¡Œæ•°ç»Ÿè®¡å’Œ hunk ä¿¡æ¯ã€‚
        
        Args:
            base_commit: åŸºå‡† commit
            new_commit: æ–° commit
            
        Returns:
            è¯¦ç»†å˜æ›´ä¿¡æ¯åˆ—è¡¨ï¼ŒåŒ…å« path, changeType, hunks å­—æ®µ
        """
        try:
            base = self.repo.commit(base_commit)
            new = self.repo.commit(new_commit)
            
            diff_index = base.diff(new, create_patch=True)
            changes = []
            
            for diff in diff_index:
                change_info = {
                    "a_path": diff.a_path,
                    "b_path": diff.b_path,
                    "change_type": self._get_change_type(diff),
                    "renamed": diff.renamed,
                    "deleted": diff.deleted_file,
                    "new_file": diff.new_file,
                }
                
                # è§£æ hunks ä¿¡æ¯
                hunks = []
                if diff.diff:
                    try:
                        diff_text = diff.diff.decode('utf-8', errors='ignore')
                        additions = diff_text.count('\n+') - diff_text.count('\n+++')
                        deletions = diff_text.count('\n-') - diff_text.count('\n---')
                        change_info["additions"] = additions
                        change_info["deletions"] = deletions
                        
                        # è§£æ hunk å¤´ï¼ˆ@@ -old_start,old_lines +new_start,new_lines @@ï¼‰
                        import re
                        hunk_pattern = r'@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@'
                        for match in re.finditer(hunk_pattern, diff_text):
                            old_start = int(match.group(1))
                            old_lines = int(match.group(2)) if match.group(2) else 1
                            new_start = int(match.group(3))
                            new_lines = int(match.group(4)) if match.group(4) else 1
                            
                            hunks.append({
                                "oldStart": old_start,
                                "oldLines": old_lines,
                                "newStart": new_start,
                                "newLines": new_lines
                            })
                    except:
                        pass
                
                change_info["hunks"] = hunks
                changes.append(change_info)
            
            return changes
        except Exception as e:
            return [{"error": str(e)}]
    
    def get_file_diff(
        self, 
        base_commit: str, 
        new_commit: str, 
        file_path: str,
        offset: int = 0,
        limit: int = 300
    ) -> str:
        """
        è·å–ç‰¹å®šæ–‡ä»¶çš„è¯¦ç»† diffã€‚æ”¯æŒåˆ†æ®µè¯»å–å¤§ diffã€‚
        
        Args:
            base_commit: åŸºå‡† commit
            new_commit: æ–° commit
            file_path: æ–‡ä»¶è·¯å¾„
            offset: èµ·å§‹è¡Œå·ï¼ˆä» 0 å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†æ®µè¯»å–
            limit: æœ€å¤šè¯»å–çš„è¡Œæ•°
            
        Returns:
            diff æ–‡æœ¬ï¼ŒåŒ…å«å…ƒä¿¡æ¯ï¼ˆæ€»è¡Œæ•°ã€å½“å‰è¯»å–èŒƒå›´ç­‰ï¼‰
        """
        try:
            result = subprocess.run(
                ['git', 'diff', f'{base_commit}..{new_commit}', '--', file_path],
                cwd=self.repo_path,
                capture_output=True,
                text=True
            )
            full_diff = result.stdout
            
            # ä½¿ç”¨ç»Ÿä¸€çš„åˆ†æ®µå¤„ç†
            lines = full_diff.split('\n')
            content, meta_info = _paginate_lines(lines, offset, limit, file_path, "Diff")
            
            return content + meta_info
        except Exception as e:
            return f"Error: {e}"
    
    def get_file_content_by_commit(
        self, 
        commit_hash: str, 
        file_path: str,
        offset: int = 0,
        limit: int = 500
    ) -> str:
        """
        è·å–ç‰¹å®š commit ä¸­æŸä¸ªæ–‡ä»¶çš„å†…å®¹ã€‚æ”¯æŒåˆ†æ®µè¯»å–å¤§æ–‡ä»¶ã€‚
        
        Args:
            commit_hash: commit å“ˆå¸Œå€¼
            file_path: æ–‡ä»¶è·¯å¾„
            offset: èµ·å§‹è¡Œå·ï¼ˆä» 0 å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†æ®µè¯»å–
            limit: æœ€å¤šè¯»å–çš„è¡Œæ•°
            
        Returns:
            æ–‡ä»¶å†…å®¹ï¼ŒåŒ…å«å…ƒä¿¡æ¯ï¼ˆæ€»è¡Œæ•°ã€å½“å‰è¯»å–èŒƒå›´ç­‰ï¼‰
        """
        try:
            commit = self.repo.commit(commit_hash)
            blob = commit.tree / file_path
            full_content = blob.data_stream.read().decode('utf-8', errors='ignore')
            
            # ä½¿ç”¨ç»Ÿä¸€çš„åˆ†æ®µå¤„ç†
            lines = full_content.split('\n')
            content, meta_info = _paginate_lines(lines, offset, limit, file_path, "æ–‡ä»¶")
            
            return content + meta_info
        except Exception as e:
            return f"Error: {e}"
    
    def get_commits_between(self, base_commit: str, new_commit: str, max_count: int = 20) -> List[Dict[str, Any]]:
        """
        è·å–ä¸¤ä¸ª commit ä¹‹é—´çš„æ‰€æœ‰ commit åˆ—è¡¨ã€‚
        
        Args:
            base_commit: åŸºå‡† commit
            new_commit: æ–° commit
            max_count: æœ€å¤šè¿”å›çš„ commit æ•°é‡
            
        Returns:
            commit ä¿¡æ¯åˆ—è¡¨
        """
        try:
            commits = list(self.repo.iter_commits(f'{base_commit}..{new_commit}', max_count=max_count))
            return [
                {
                    "hash": c.hexsha[:8],
                    "author": str(c.author),
                    "date": c.committed_datetime.isoformat(),
                    "message": c.summary
                }
                for c in commits
            ]
        except Exception as e:
            return [{"error": str(e)}]
    
    def get_file_history(self, file_path: str, max_count: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æ–‡ä»¶çš„ä¿®æ”¹å†å²ã€‚
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            max_count: æœ€å¤šè¿”å›çš„å†å²è®°å½•æ•°
            
        Returns:
            ä¿®æ”¹å†å²åˆ—è¡¨
        """
        try:
            commits = list(self.repo.iter_commits(paths=file_path, max_count=max_count))
            return [
                {
                    "hash": c.hexsha[:8],
                    "author": str(c.author),
                    "date": c.committed_datetime.isoformat(),
                    "message": c.summary
                }
                for c in commits
            ]
        except Exception as e:
            return [{"error": str(e)}]
    
    def _get_change_type(self, diff) -> str:
        """åˆ¤æ–­å˜æ›´ç±»å‹"""
        if diff.new_file:
            return "ADD"
        elif diff.deleted_file:
            return "DELETE"
        elif diff.renamed:
            return "RENAME"
        else:
            return "MODIFY"
    
    def get_current_ref(self) -> str:
        """
        è·å–å½“å‰ Git å¼•ç”¨ã€‚
        
        Returns:
            åˆ†æ”¯åï¼ˆå¦‚ "main"ï¼‰æˆ– commit hashï¼ˆdetached HEADï¼‰
        """
        if self.repo.head.is_detached:
            # detached HEAD çŠ¶æ€ï¼Œè¿”å› commit hash
            return self.repo.head.commit.hexsha
        else:
            # åœ¨æŸä¸ªåˆ†æ”¯ä¸Šï¼Œè¿”å›åˆ†æ”¯å
            return self.repo.active_branch.name

    def checkout_version(self, ref: str):
        """
        åˆ‡æ¢åˆ°æŒ‡å®šç‰ˆæœ¬ã€‚
        
        Args:
            ref: ç‰ˆæœ¬å·ï¼ˆcommit hash æˆ–åˆ†æ”¯åï¼‰
        """
        self.repo.git.checkout(ref)

class AnalyzerAPITools:
    """æºç åˆ†æ REST API å·¥å…·å‡½æ•°"""
    
    def __init__(self, base_url: str = "http://localhost:8089"):
        self.base_url = base_url.rstrip("/")
    
    def index_project(self, repo_path: str) -> Dict[str, Any]:
        """
        ç´¢å¼•é¡¹ç›®ï¼Œæ„å»ºè°ƒç”¨å›¾ã€‚
        
        Args:
            repo_path: é¡¹ç›®æ ¹è·¯å¾„
            
        Returns:
            ç´¢å¼•çŠ¶æ€
        """
        try:
            url = f"{self.base_url}/index/project"
            payload = {
                "rootPath": repo_path,
                "sourceSets": ["main"],
                "maven": {"resolveDeps": True},
                "jdkHome": None
            }
            print(f"\nğŸŒ API è°ƒç”¨: POST {url}")
            print(f"ğŸ“¦ è¯·æ±‚ä½“: {payload}")
            
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def get_index_status(self) -> Dict[str, Any]:
        """
        è·å–ç´¢å¼•çŠ¶æ€ã€‚
        
        Returns:
            ç´¢å¼•çŠ¶æ€ä¿¡æ¯
        """
        try:
            url = f"{self.base_url}/index/status"
            print(f"\nğŸŒ API è°ƒç”¨: GET {url}")
            
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def map_hunks_to_symbols(self, changes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å°†æ–‡ä»¶å˜æ›´æ˜ å°„åˆ°å—å½±å“çš„æ–¹æ³•å’Œç±»ã€‚
        
        Args:
            changes: å˜æ›´åˆ—è¡¨ï¼ˆFileChange æ ¼å¼ï¼‰
            
        Returns:
            æ˜ å°„ç»“æœï¼ŒåŒ…å« affected æ–¹æ³•å’Œç±»
        """
        try:
            url = f"{self.base_url}/map/hunks-to-symbols"
            payload = {"changes": changes}
            
            # è¯¦ç»†è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
            print(f"\nğŸ“‹ ç­›é€‰åçš„å˜æ›´æ–‡ä»¶åˆ—è¡¨ ({len(changes)} ä¸ª):")
            for i, change in enumerate(changes, 1):
                # å…¼å®¹ä¸¤ç§æ ¼å¼ï¼špath/changeTypeï¼ˆæ ‡å‡†æ ¼å¼ï¼‰å’Œ b_path/a_path/change_typeï¼ˆå†…éƒ¨æ ¼å¼ï¼‰
                path = change.get('path') or change.get('b_path') or change.get('a_path') or 'unknown'
                change_type = change.get('changeType') or change.get('change_type') or 'UNKNOWN'
                # å¤„ç†å¯èƒ½çš„ None å€¼
                additions = change.get('additions')
                deletions = change.get('deletions')
                
                # æ ¼å¼åŒ–ç»Ÿè®¡ä¿¡æ¯
                if additions is not None and deletions is not None:
                    stats = f"(+{additions:3d}/-{deletions:3d})"
                elif additions is not None:
                    stats = f"(+{additions} lines)"
                elif deletions is not None:
                    stats = f"(-{deletions} lines)"
                else:
                    stats = ""
                
                print(f"   {i:2d}. {path:<60} [{change_type:6}] {stats}")
            
            print(f"\nğŸŒ API è°ƒç”¨: POST {url}")
            print(f"ğŸ“¦ è¯·æ±‚ä½“: {len(changes)} ä¸ªæ–‡ä»¶å˜æ›´")
            
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def analyze_impact(
        self,
        seeds: Dict[str, Any],
        depth: int = 1,
        direction: str = "outbound",
        include_edges: bool = True
    ) -> Dict[str, Any]:
        """
        åˆ†æå½±å“èŒƒå›´ã€‚
        
        Args:
            seeds: ç§å­æ–¹æ³•/ç±»
            depth: ä¼ æ’­æ·±åº¦
            direction: æ–¹å‘ï¼ˆinbound/outbound/bothï¼‰
            include_edges: æ˜¯å¦åŒ…å«è°ƒç”¨è¾¹
            
        Returns:
            å½±å“åˆ†æç»“æœ
        """
        try:
            url = f"{self.base_url}/analyze/impact"
            payload = {
                "seeds": seeds,
                "direction": direction,
                "depth": depth,
                "includeEdges": include_edges
            }
            print(f"\nğŸŒ API è°ƒç”¨: POST {url}")
            print(f"ğŸ“¦ è¯·æ±‚ä½“: seeds={seeds}, depth={depth}, direction={direction}")
            
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"error": str(e)}


class SourceCodeTools:
    """æºç è¯»å–ç›¸å…³å·¥å…·"""
    
    def __init__(self, repo_path: str):
        self.repo_path = Path(repo_path)
    
    def read_file(self, relative_path: str, max_lines: int = 500, offset: int = 0) -> str:
        """
        è¯»å–é¡¹ç›®ä¸­çš„æ–‡ä»¶å†…å®¹ã€‚æ”¯æŒåˆ†æ®µè¯»å–å¤§æ–‡ä»¶ã€‚
        
        Args:
            relative_path: ç›¸å¯¹äºé¡¹ç›®æ ¹çš„è·¯å¾„
            max_lines: æœ€å¤šè¯»å–çš„è¡Œæ•°ï¼ˆæ¯æ¬¡è¯»å–çš„é™åˆ¶ï¼‰
            offset: èµ·å§‹è¡Œå·ï¼ˆä» 0 å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†æ®µè¯»å–
            
        Returns:
            æ–‡ä»¶å†…å®¹ï¼ŒåŒ…å«å…ƒä¿¡æ¯ï¼ˆæ€»è¡Œæ•°ã€å½“å‰è¯»å–èŒƒå›´ç­‰ï¼‰
        """
        try:
            file_path = self.repo_path / relative_path
            if not file_path.exists():
                return f"Error: File not found: {relative_path}"
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ä½¿ç”¨ç»Ÿä¸€çš„åˆ†æ®µå¤„ç†
            lines = content.split('\n')
            paginated_content, meta_info = _paginate_lines(lines, offset, max_lines, relative_path, "æ–‡ä»¶")
            
            return paginated_content + meta_info
            
        except Exception as e:
            return f"Error: {e}"
    
    def search_in_file(self, relative_path: str, keyword: str) -> List[Dict[str, Any]]:
        """
        åœ¨æ–‡ä»¶ä¸­æœç´¢å…³é”®å­—ã€‚
        
        Args:
            relative_path: æ–‡ä»¶è·¯å¾„
            keyword: æœç´¢å…³é”®å­—
            
        Returns:
            åŒ¹é…çš„è¡Œä¿¡æ¯åˆ—è¡¨
        """
        try:
            file_path = self.repo_path / relative_path
            if not file_path.exists():
                return [{"error": f"File not found: {relative_path}"}]
            
            matches = []
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if keyword in line:
                        matches.append({
                            "line_number": line_num,
                            "content": line.strip()
                        })
            
            return matches
        except Exception as e:
            return [{"error": str(e)}]
    
    def list_java_files(self, directory: str = "") -> List[str]:
        """
        åˆ—å‡ºç›®å½•ä¸‹çš„æ‰€æœ‰ Java æ–‡ä»¶ã€‚
        
        Args:
            directory: ç›¸å¯¹ç›®å½•è·¯å¾„
            
        Returns:
            Java æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            search_path = self.repo_path / directory if directory else self.repo_path
            java_files = []
            
            for path in search_path.rglob("*.java"):
                relative_path = path.relative_to(self.repo_path)
                java_files.append(str(relative_path))
            
            return sorted(java_files)
        except Exception as e:
            return [f"Error: {e}"]
    
    def list_directory(self, directory: str = "") -> Dict[str, Any]:
        """
        åˆ—å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶å’Œå­ç›®å½•ã€‚
        
        Args:
            directory: ç›¸å¯¹ç›®å½•è·¯å¾„ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé¡¹ç›®æ ¹ç›®å½•
            
        Returns:
            åŒ…å«ç›®å½•å†…å®¹çš„å­—å…¸
        """
        try:
            target_path = self.repo_path / directory if directory else self.repo_path
            
            if not target_path.exists():
                return {"error": f"ç›®å½•ä¸å­˜åœ¨: {directory or '.'}"}
            
            if not target_path.is_dir():
                return {"error": f"ä¸æ˜¯ç›®å½•: {directory or '.'}"}
            
            items = []
            for item in sorted(target_path.iterdir()):
                try:
                    relative = item.relative_to(self.repo_path)
                    if item.is_dir():
                        items.append({
                            "type": "directory",
                            "name": item.name,
                            "path": str(relative)
                        })
                    else:
                        size = item.stat().st_size
                        items.append({
                            "type": "file",
                            "name": item.name,
                            "path": str(relative),
                            "size": size
                        })
                except Exception:
                    # å¿½ç•¥æ— æ³•è®¿é—®çš„æ–‡ä»¶
                    continue
            
            return {
                "directory": directory or ".",
                "total_items": len(items),
                "directories": [i for i in items if i["type"] == "directory"],
                "files": [i for i in items if i["type"] == "file"]
            }
        except Exception as e:
            return {"error": str(e)}
    
    def find_file(self, pattern: str, max_results: int = 200) -> Dict[str, Any]:
        """
        åœ¨é¡¹ç›®ä¸­æŸ¥æ‰¾ç‰¹å®šæ–‡ä»¶åã€‚
        
        Args:
            pattern: æ–‡ä»¶åæ¨¡å¼ï¼Œæ”¯æŒé€šé…ç¬¦
            max_results: æœ€å¤šè¿”å›çš„ç»“æœæ•°
            
        Returns:
            åŒ…å«åŒ¹é…æ–‡ä»¶çš„å­—å…¸
        """
        import fnmatch
        
        try:
            matches = []
            
            # é€’å½’æœç´¢æ‰€æœ‰æ–‡ä»¶
            for file_path in self.repo_path.rglob("*"):
                if file_path.is_file():
                    relative = file_path.relative_to(self.repo_path)
                    # åŒ¹é…æ–‡ä»¶åæˆ–å®Œæ•´è·¯å¾„
                    if fnmatch.fnmatch(file_path.name, pattern) or fnmatch.fnmatch(str(relative), pattern):
                        matches.append({
                            "name": file_path.name,
                            "path": str(relative),
                            "size": file_path.stat().st_size
                        })
                        if len(matches) >= max_results:
                            break
            
            result = {
                "pattern": pattern,
                "found_count": len(matches),
                "files": matches
            }
            
            if len(matches) >= max_results:
                result["note"] = f"æœç´¢å·²è¾¾åˆ°ä¸Šé™ï¼Œä»…æ˜¾ç¤ºå‰ {max_results} ä¸ªç»“æœ"
            elif len(matches) == 0:
                result["note"] = f"æœªæ‰¾åˆ°åŒ¹é… '{pattern}' çš„æ–‡ä»¶"
            
            return result
        except Exception as e:
            return {"error": f"æœç´¢å¤±è´¥: {str(e)}"}


def get_all_tools(repo_path: str, api_base_url: str = "http://localhost:8089") -> Dict[str, Any]:
    """
    è·å–æ‰€æœ‰å·¥å…·å®ä¾‹ã€‚
    
    Args:
        repo_path: é¡¹ç›®è·¯å¾„
        api_base_url: API åŸºç¡€ URL
        
    Returns:
        å·¥å…·å­—å…¸
    """
    return {
        "git": GitTools(repo_path),
        "api": AnalyzerAPITools(api_base_url),
        "source": SourceCodeTools(repo_path)
    }
